{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9fa800b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "def get_data(file=\"data/Train.csv\", fraction=1, drop=[], seed=42):\n",
    "    df = pd.read_csv(file, parse_dates=[\"Date\"],date_format=\"%Y-%m-%d\" )\n",
    "    df[\"Date\"] = df[\"Date\"].values.astype(np.int64) // 10**9\n",
    "    df = df.sample(frac=fraction, random_state=seed)\n",
    "    df = df.drop(drop, axis=1)\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec84a784",
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_outliers_sigma(df, column, n_sigma=3):\n",
    "    \"\"\"\n",
    "    Identify outliers using n-sigma rule\n",
    "    Values beyond mean Â± n*std are considered outliers\n",
    "    \"\"\"\n",
    "    mean = df[column].mean()\n",
    "    std = df[column].std()\n",
    "    \n",
    "    lower_bound = mean - (n_sigma * std)\n",
    "    upper_bound = mean + (n_sigma * std)\n",
    "    \n",
    "    # Create boolean mask for outliers\n",
    "    #outliers = (df[column] < lower_bound) | (df[column] > upper_bound)\n",
    "    \n",
    "    return lower_bound, upper_bound\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe9a6916",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "from sklearn.model_selection import train_test_split\n",
    "def split(dataframe, target, stratify,seed=42):\n",
    "    target = \"target\"\n",
    "    \n",
    "\n",
    "    y = dataframe[target]\n",
    "    X = dataframe.drop(target, axis=1)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=seed,stratify=stratify )\n",
    "\n",
    "    #df_train = pd.concat((X_train,y_train), axis=1)\n",
    "    return  X_train, X_test, y_train, y_test\n",
    "    #df_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0112cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def column_threshold(dataframe,threshold,drop, excludes):\n",
    "    # features to be encoded\n",
    "\n",
    "\n",
    "    # derive list of columns with more than X % of not null values\n",
    "    columns = {\"column\":[], \"not_null\": [], \"exclude\":[]}\n",
    "    column_list = dataframe.columns.to_list()\n",
    "    for column in column_list:\n",
    "        excl=False\n",
    "        for exclude in excludes:\n",
    "            if exclude in column:\n",
    "                excl = True                \n",
    "        \n",
    "        columns[\"column\"].append(column)\n",
    "        columns[\"not_null\"].append(dataframe[column].count()/dataframe['target'].count()*100)\n",
    "        columns[\"exclude\"].append(excl)\n",
    "\n",
    "    cols=pd.DataFrame(columns)\n",
    "    features_to_use=list(set(cols[(cols[\"not_null\"]>threshold)&(cols[\"exclude\"]==False)][\"column\"])-set([\"target\"])-set(drop))\n",
    "    return features_to_use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ccdd4ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, PowerTransformer, OneHotEncoder, PolynomialFeatures, FunctionTransformer, QuantileTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import r2_score, root_mean_squared_error\n",
    "import time\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import scipy.stats as stats\n",
    "\n",
    "\n",
    "def run_models(model_name, model_class, scaler, features_categorical,features_numeric,X_train, y_train, X_test, y_test ):\n",
    "\n",
    "    if model_name == \"Linear Regression 1\":\n",
    "        param_dist = {'copy_X': [True,False], \n",
    "                   'fit_intercept': [True,False], \n",
    "                   'n_jobs': [1,5,10,15,None], \n",
    "                   'positive': [True,False]}\n",
    "    elif model_name == \"XGBoost\":\n",
    "        param_dist = {\n",
    "            'model__max_depth': stats.randint(3, 10),\n",
    "            'model__learning_rate': stats.uniform(0.01, 0.1),\n",
    "            'model__subsample': stats.uniform(0.5, 0.5),\n",
    "            'model__n_estimators':stats.randint(50, 200)\n",
    "        }\n",
    "    \n",
    "    #print(features_num_key, features_numeric)\n",
    "    start_time = time.time()\n",
    "    encode_location = Pipeline([ \n",
    "        (\"encode\", OneHotEncoder(drop=\"first\"))]) \n",
    "    \n",
    "    scale_impute = Pipeline([   \n",
    "        (\"imputer_null\",KNNImputer(n_neighbors=10, weights=\"distance\")), # deals with null  \n",
    "        (\"imputer_0\",KNNImputer(n_neighbors=10, weights=\"distance\", missing_values=0)), # deals with 0  \n",
    "        (\"scaler\", scaler )\n",
    "        ]) \n",
    "    preprocess = ColumnTransformer([    \n",
    "        (\"scale_impute\", scale_impute, features_numeric),\n",
    "        (\"encode_location\", encode_location, features_categorical)],remainder=\"drop\")\n",
    "    \n",
    "    regression = Pipeline([ \n",
    "        ('preprocess', preprocess), \n",
    "        ('model', model_class)])\n",
    "    \n",
    "    search_reg = RandomizedSearchCV(regression, param_distributions=param_dist, cv=5, scoring='r2', verbose=1, n_jobs=-1, n_iter=10)\n",
    "\n",
    "    search_reg.fit(X_train, y_train)\n",
    "    best_model = search_reg.best_estimator_\n",
    "    pred = best_model.predict(X_test)\n",
    "    #pred = regression.predict(X_test) \n",
    "    '''\n",
    "    coefficients={\"columns\":[],\"numbers\":[]}\n",
    "    if model_name==\"XGBoost\":\n",
    "        coefficients[\"numbers\"] = regression.named_steps[\"model\"][0].feature_importances_\n",
    "        coefficients[\"columns\"] = regression[:-1].get_feature_names_out()\n",
    "        \n",
    "    elif model_name==\"Polynomial Linear Regression\":\n",
    "        coefficients[\"numbers\"] = regression.named_steps[\"model\"][1].coef_\n",
    "        coefficients[\"columns\"] = regression.named_steps[\"model\"][0].get_feature_names_out()\n",
    "  \n",
    "    \n",
    "    coefficients = pd.DataFrame(coefficients)\n",
    "    coefficients[\"numbers\"]=coefficients[\"numbers\"].abs()\n",
    "    coefficients=coefficients.sort_values(by=\"numbers\",ascending=False)\n",
    "    coefficients[\"columns\"]=coefficients[\"columns\"].replace(to_replace=\"scale_impute__\",value=\"\", regex=True).replace(to_replace=\"encode_location__\",value=\"\", regex=True)\n",
    "    coefficients=\", \".join(coefficients[\"columns\"].head(3).to_list())\n",
    "    '''\n",
    "\n",
    "    r2 = r2_score(y_test, pred)*100\n",
    "    rmse =root_mean_squared_error(y_test, pred)\n",
    "    end_time = time.time()\n",
    "    duration = round(end_time-start_time,0)\n",
    "    return r2, rmse, duration#, coefficients\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c99086a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')  # Suppress all warnings\n",
    "#from sklearn.metrics.pairwise import rbf_kernel\n",
    "\n",
    "fraction=1\n",
    "column_threshold_not_null = [20]\n",
    "column_exclusion ={\"sat geometry\":[\"angle\", \"altitude\"]}\n",
    "scaler = {\"power\":make_pipeline(PowerTransformer())}\n",
    "target_outlier_sigma = 3\n",
    "\n",
    "target = \"target\"\n",
    "drop=[\"Place_ID X Date\",\"target_min\",\"target_max\",\"target_variance\",\"target_count\"]\n",
    "\n",
    "file = \"data/Train.csv\"\n",
    "seed=2\n",
    "features_categorical = [\"Place_ID\"]\n",
    "\n",
    "df = get_data(file=file,fraction=fraction, drop=drop, seed=seed)\n",
    "df[target]=np.log10(df[target])\n",
    "\n",
    "X_train, X_test, y_train, y_test = split(dataframe=df, target=target,stratify=df[features_categorical], seed=seed)\n",
    "df_train = pd.concat((X_train,y_train), axis=1)\n",
    "target_min,target_max=identify_outliers_sigma(df_train, target, target_outlier_sigma)\n",
    "df_train = df_train[(df_train[target]>=target_min)&(df_train[target]<=target_max)]\n",
    "\n",
    "X_train = df_train.drop(target,axis=1)\n",
    "y_train = df_train[target]\n",
    "\n",
    "\n",
    "objective = 'reg:squarederror'\n",
    "models ={\"XGBoost\": xgb.XGBRegressor()  \n",
    "        ,\"Linear Regression 1\": LinearRegression()\n",
    "        #,\"Polynomial Linear Regression 2\": make_pipeline(PolynomialFeatures(degree=2), LinearRegression())\n",
    "        #,'Random Forest': make_pipeline(RandomForestRegressor(n_estimators=100,min_impurity_decrease=0.1, random_state=42))\n",
    "        #,'SVR': make_pipeline(SVR())\n",
    "        #,\"Gradient Boost Regressor\" : GradientBoostingRegressor()\n",
    "        #,\"LGBoost\": make_pipeline(lgb.LGBMRegressor())\n",
    "        }\n",
    "\n",
    "results =  {\"model\":[],\"scaler\":[], \"R2\":[], \"RMSE\":[],\"duration\":[],\"not null gt\":[],\"exclude\":[],\"columns\":[]}#, \"coefficients\":[]}\n",
    "\n",
    "for model_name, model_class in models.items():\n",
    "        for scaler_key,scaler_value in scaler.items():\n",
    "                for threshold in column_threshold_not_null:\n",
    "                        for ex_key, ex_val in column_exclusion.items():\n",
    "                                features_other = column_threshold(dataframe=df,threshold=threshold,drop=features_categorical, excludes=ex_val)\n",
    "                                r2, rmse, duration = run_models(model_name, model_class,scaler_value,  features_categorical,features_other,X_train, y_train, X_test, y_test )\n",
    "                                results[\"model\"].append(model_name)\n",
    "                                results[\"scaler\"].append(scaler_key)\n",
    "                                results[\"R2\"].append(r2)\n",
    "                                results[\"RMSE\"].append(rmse)\n",
    "                                results[\"duration\"].append(duration)\n",
    "                                results[\"not null gt\"].append(threshold)\n",
    "                                results[\"exclude\"].append(ex_key)\n",
    "                                results[\"columns\"].append(len(features_other)\n",
    "                                                          )\n",
    "\n",
    "#                results[\"coefficients\"].append(coefficients)\n",
    "                \n",
    "results=pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f9a8dcef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>scaler</th>\n",
       "      <th>R2</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>duration</th>\n",
       "      <th>not null gt</th>\n",
       "      <th>exclude</th>\n",
       "      <th>columns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>power</td>\n",
       "      <td>69.853223</td>\n",
       "      <td>0.187254</td>\n",
       "      <td>377.0</td>\n",
       "      <td>20</td>\n",
       "      <td>sat geometry</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     model scaler         R2      RMSE  duration  not null gt       exclude   \n",
       "0  XGBoost  power  69.853223  0.187254     377.0           20  sat geometry  \\\n",
       "\n",
       "   columns  \n",
       "0       37  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.max_colwidth = 500\n",
    "pd.set_option('display.max_rows', None)\n",
    "#results.to_csv(\"results/results_with_y_outlier.csv\")\n",
    "results.to_csv(\"results/final_results_wo_y_outlier.csv\")\n",
    "results.sort_values(by=[\"R2\",\"RMSE\"], ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
